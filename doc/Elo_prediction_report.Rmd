---
title: "Predicting NFL game winners with ELO rating"
author: "Frank Lu, Simardeep Kaur, Tani Barasch </br>"
date: "2020/01/25 (updated: `r Sys.Date()`)"
always_allow_html: true
output: 
  html_document:
    toc: true
bibliography: #breast_cancer_refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(kableExtra)
library(tidyverse)
library(caret)
library(reticulate)
library(dplyr)
```

```{r load model results}
score_rf <- read.delim("data/rf_score.csv")
score_lr <- read.delim("data/lr_score.csv")
```

# Summary

In this project we attempt to predict NFL game winners using classification algorithems, Random Forest and Logistic Regression, in order to test the hypothesis that ELO ratings can be used to predict the outcome as presented by the website FiveThirtyEight.com in their 'NFL Prediction Game'.
-- add something about conclusions later -- 

#########
tif: Here we attempt to build a classification model using the k-nearest neighbours algorithm which can use breast cancer tumour image measurements to predict whether a newly discovered breast cancer tumour is benign (i.e., is not harmful and does not require treatment) or malignant (i.e., is harmful and requires treatment intervention). Our final classifier performed fairly well on an unseen test data set, with Cohen's Kappa score of "r round(model_quality$overall[2], 1)` and an overall accuracy calculated to be r round(model_quality$overall[1], 2)`. On the r sum(model_quality$table)` test data cases, it correctly predicted  r model_quality$table[2, 2] + model_quality$table[1, 1]`. However it incorrectly predicted  r model_quality$table[2, 1] + model_quality$table[1, 2]` cases, and importantly these cases were false negatives; predicting that a tumour is benign when in fact it is malignant. These kind of incorrect predictions could have a severly negative impact on a patients health outcome, thus we recommend continuing study to improve this prediction model before it is put into production in the clinic.
#########

# Introduction

The sport of american football has succesfully built a reputation of an unpredictable sport where every game is important and anyone can win, coining the saying "any given Sunday" to mean that anything can happen on a football field, which are usually played on Sundays in the National Football League (NFL). Having several movies being made to this theme such as "Any Given Sunday" (1999), "Remember the Titans" (2000), or more recently the Netflix documentry "Last Chance U" (2016).
At the begining of the 2019 seas the website FiveThirtyEight launched a "Prediction Game" [] for its readers, in which the website uses the ELO ranking system and prediction formulas to assign a win probability to each team for each game.

In order to test whether or not the hypothesis that NFL games can be predicted using this ELO system, as presented by FiveThirtyEight we train two machine learning classification algorithems, Random Forest and Logistic Regression in order to test the success rate of such algorithems, doing so using only pregame elo ratings for the teams and the starting quarterbacks.

############
Women have a 12.1% lifetime probability of developing breast cancer, and although cancer treatment has improved over the last 30 years, the projected death rate for women's breast cancer is 22.4 deaths per 100,000 in 2019 [@ccsac]. Early detection has been shown to improve outcomes [@ccsac], and thus methods, assays and technologies that help to improve diagnosis may be beneficial for improving outcomes further. 

Here we ask if we can use a machine learning algorithm to predict whether a newly discovered tumour is benign or malignant given tumour image measurements. Answering this question is important because traditional methods for tumour diagnosis are quite subjective and can depend on the diagnosing physicians skill as well as experience [@Streetetal]. Furthermore, benign tumours are not normally dangerous; the cells stay in the same place and the tumour stops growing before it gets very large. By contrast, in malignant tumours, the cells invade the surrounding tissue and spread into nearby organs where they can cause serious damage. Thus, if a machine learning algorithm can accurately and effectively predict whether a newly discovered tumour benign or malignant given tumour image measurements this could lead to less subjective, and more scalable breast cancer tumour diagnosis which could contribute to better patient outcomes.
############

# Methods

## Data
The data set used to train and test our algorithems is the same data used by FiveThirtyEight in their game, which can be found [here](https://github.com/fivethirtyeight/data/tree/master/nfl-elo). Specifically the file found [here](https://projects.fivethirtyeight.com/nfl-api/nfl_elo.csv) containing historic nfl ratings and outcomes starting in 1920 was used to train the algorithems, and testing the predictions were done on the following file containing all [2019-2020](https://projects.fivethirtyeight.com/nfl-api/nfl_elo_latest.csv) NFL games and outcomes (excluding the superbowl which has yet to be played.) 

Each row in each file containins the ELO ratings pre and post game for the two NFL teams and starting Quarterbacks participating in that specific game, along with the date, season, and final score of the game. Where the Home team is logged as team1 and the away team as team2.


## Analysis
We have used two classification models to see how the elo ratings will affect the the predicted scores.
The Python [!!!] programming language, using the Scikit-Learn package [!!!] we trained a Logistic regression and Random Forest classification algorithems. Since it would be redundent to predict both winner and loser for a single game, all predictions were made in relation to the home team, with 3 possible outcomes: Win, Tie, Lose.
For the data used to train the model, all seasons prior to the 1970 NFL merger were filtered out, only using data since the NFL started its  shift towards the structure that is used today, with teams split into two confrences, mostly playing against other teams in their confrence.

###Variables used:
From the original file, any variable relating to the outcome of the game was removed, such as post game elo score, each teams actual score etc'. In addition information which uniquely identifies a team outside of the ELO framework, such as team name and QB name, was removed since it could bias the results by giving information about which teams are performing better. So, removing this identifiers for different teams was an important step to get unbiased results.

###Hyperparameters:
For the Random Forest modle, the hyperparameter “max_depth” is chosen using k-fold cross validation using k=5. The best hyperparameter was then used to train the model.

The code used to run the training and testing of the algorithems can be found at the projects github repo [here](https://github.com/UBC-MDS/Workflows_Group_306): 
!!!! add refrences and citations !!!

# Results & Discussion

To look at whether each of the predictors might be useful to predict the tumour class, we plotted the distributions of each predictor from the training data set and coloured the distribution by class (benign: blue and malignant: orange). In doing this we see that class distributions for all of the mean and max predictors for all the measurements overlap somewhat, but do show quite a difference in their centres and spreads. This is less so for the standard error (se) predictors. In particular, the standard errors of fractal dimension, smoothness, symmetry and texture look very similar in both the distribution centre and spread. Thus, we choose to omit these from our model.

```{r predictor-distributions, echo=FALSE, fig.cap="Figure 1. Comparison of the empirical distributions of training data predictors between benign and malignant tumour masses.", out.width = '100%'}
#knitr::include_graphics("../results/predictor_distributions_across_class.png")
```

We chose to use a simple classification model using the k-nearest neighbours algorithm. To find the model that best predicted whether a tumour was benign or malignant, we performed 30-fold cross validation using Cohen's Kappa as our metric of model prediction performance to select K (number of nearest neighbours). We observed that the optimal K was r model$bestTune$k`.

```{r choosing-k, echo=FALSE, fig.cap="Figure 2. Results from 30-fold cross validation to choose K. Cohen's Kappa was used as the classification metric as K was varied.", out.width = '60%'}
#knitr::include_graphics("../results/kappa_vs_k.png")
```

Our prediction model performed quite well on test data, with a final Cohen's Kappa score of r round(model_quality$overall[2], 1)` and an overall accuracy calculated to be r round(model_quality$overall[1], 2)`. Other indicators that our model performed well come from the confusion matrix, where it only made r model_quality$table[2, 1] + model_quality$table[1, 2]` mistakes. However all r model_quality$table[2, 1] + model_quality$table[1, 2]` mistakes were predicting a malignant tumour as benign, given the implications this has for patients health, this model is not good enough to yet implement in the clinic.


```{ confusion-matrix, echo=FALSE}
kable(model_quality$table, caption = "Table 1. Confusion matrix of model performance on test data.") %>%
  kable_styling(full_width = FALSE) %>%
  add_header_above(c(" ", "Reference" = 2)) %>% 
  pack_rows("Predicted", 1, 2)
```

To further improve this model in future with hopes of arriving one that could be used in the clinic, there are several things we can suggest. First, we could look closely at the 4 misclassified observations and compare them to several observations that were classified correctly (from both classes). The goal of this would be to see which feature(s) may be driving the misclassification and explore whether any feature engineering could be used to help the model better predict on observations that it currently is making mistakes on. Additionally, we would try seeing whether we can get improved predictions using other classifiers. One classifier we might try is random forest forest because it automatically allows for feature interaction, where k-nn does not. Finally, we also might improve the usability of the model in the clinic if we output and report the probability estimates for predictions. If we cannot prevent misclassifications through the approaches suggested above, at least reporting a probability estimates for predictions would allow the clinician to know how confident the model was in its prediction. Thus the clinician may then have the ability to perform additional diagnostic assays if the probability estimates for prediction of a given tumour class is not very high.

# References

